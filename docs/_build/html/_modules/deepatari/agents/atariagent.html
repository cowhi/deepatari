

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>deepatari.agents.atariagent &mdash; deepatari 0.1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../../_static/fix_rtd.css" type="text/css" />
  

  
    <link rel="top" title="deepatari 0.1.0 documentation" href="../../../index.html"/>
        <link rel="up" title="Module code" href="../../index.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> deepatari
          

          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../help/install.html">Installation guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/experiment.html">Experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/agent.html">Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/environment.html">Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/learner.html">Learner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/memory.html">Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/statistics.html">Statistics</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../authors.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../changes.html">Changelog</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../../index.html">deepatari</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      
    <li>deepatari.agents.atariagent</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for deepatari.agents.atariagent</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1">#import random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.agent</span> <span class="kn">import</span> <span class="n">Agent</span>
<span class="kn">from</span> <span class="nn">.ataristatebuffer</span> <span class="kn">import</span> <span class="n">AtariStateBuffer</span>

<div class="viewcode-block" id="AtariAgent"><a class="viewcode-back" href="../../../modules/agent.html#deepatari.agents.atariagent.AtariAgent">[docs]</a><span class="k">class</span> <span class="nc">AtariAgent</span><span class="p">(</span><span class="n">Agent</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; This class is an implementation of an Atari agent.</span>

<span class="sd">    The agent interacts with the given environment, organizes the trainig of the</span>
<span class="sd">    network and sends information to the statistics.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        buf (AtariStateBuffer): Simple buffer of sequence_length to concatenate frames to form the current state.</span>
<span class="sd">        n_avail_actions (int): Number of available actions for the agent to select for a specific environment.</span>
<span class="sd">        avail_actions (tuple[int]): The IDs of the availabe actions.</span>
<span class="sd">        train_all (bool): Indicates if the network uses all possible actions as output or only the available ones.</span>
<span class="sd">        random_starts (int): Perform max this number of dummy actions at beginning of an episode to produce more random game dynamics.</span>
<span class="sd">        sequence_length (int): Determines how many frames form a state.</span>
<span class="sd">        epsilon_start (float): Start value of the exploration rate (epsilon).</span>
<span class="sd">        epsilon_end (float): Final value of the exploration rate (epsilon).</span>
<span class="sd">        epsilon_decay_steps (int): Number of steps from epsilon_start to epsilon_end.</span>
<span class="sd">        epsilon_test (float): Exploration rate (epsilon) during the test phase.</span>
<span class="sd">        train_frequency (int): Perform training after this many game steps.</span>
<span class="sd">        train_repeat (int): Number of times to sample minibatch during training.</span>

<span class="sd">    Note:</span>
<span class="sd">        More attributes of this class are defined in the base class Agent.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;AtariAgent&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initializes an agent for the Atari environment.</span>

<span class="sd">        Args:</span>
<span class="sd">            env (AtariEnv): The envirnoment in which the agent actuates.</span>
<span class="sd">            mem (ReplayMemory): The replay memory to save the experiences.</span>
<span class="sd">            net (Learner): Object of one of the Learner modules.</span>
<span class="sd">            args (argparse.Namespace): All settings either with a default value or set via command line arguments.</span>
<span class="sd">            rng (mtrand.RandomState): initialized Mersenne Twister pseudo-random number generator.</span>
<span class="sd">            name (str): The name of the network object.</span>

<span class="sd">        Note:</span>
<span class="sd">            This function should always call the base class first to initialize</span>
<span class="sd">            the common values for the networks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing new object of type &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__name__</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AtariAgent</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">mem</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">rng</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span> <span class="o">=</span> <span class="n">AtariStateBuffer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_avail_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">n_avail_actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avail_actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">avail_actions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_all</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">train_all</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_starts</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">random_starts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">sequence_length</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">epsilon_start</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">epsilon_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">epsilon_decay_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_test</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">epsilon_test</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_frequency</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">train_frequency</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_repeat</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">train_repeat</span>

        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_do_dummy_steps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Do some dummy steps at the beginning of each new episode for better randomization. &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Restarting environment with a number of dummy actions&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset_env</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">random_starts</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">get_current_frame</span><span class="p">()</span>
            <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">is_state_terminal</span><span class="p">()</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">terminal</span><span class="p">,</span> <span class="s2">&quot;terminal state occurred during random initialization&quot;</span>
            <span class="c1"># add dummy states to buffer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_epsilon</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Update the exploration rate (epsilon) with regard to the decay rate</span>

<span class="sd">        Returns:</span>
<span class="sd">            epsilon (float): Upated epsilon value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Updating exploration rate&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps_total</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps_total</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_start</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_decay_steps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon_end</span>

<div class="viewcode-block" id="AtariAgent.step"><a class="viewcode-back" href="../../../modules/agent.html#deepatari.agents.atariagent.AtariAgent.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Perform one step in the environment, send the results to the buffer and update the stats.</span>

<span class="sd">        Args:</span>
<span class="sd">            epsilon (float): The current epsilon value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Epsilon </span><span class="si">%f</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="n">epsilon</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="n">how</span> <span class="o">=</span> <span class="s2">&quot;random&quot;</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avail_actions</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># if not random choose action with highest Q-value</span>
            <span class="n">how</span> <span class="o">=</span> <span class="s2">&quot;predicted&quot;</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="o">.</span><span class="n">get_current_state</span><span class="p">()</span>
            <span class="n">qvalues</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">get_Q</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;qvalues shape = </span><span class="si">%s</span><span class="s2">, type = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">qvalues</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span><span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">qvalues</span><span class="p">))))</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">qvalues</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Qvalues not as expected -&gt; &quot;</span> <span class="o">+</span> <span class="n">qvalues</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_all</span><span class="p">:</span>
                <span class="n">qvalues</span> <span class="o">=</span> <span class="n">qvalues</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avail_actions</span><span class="p">)]</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avail_actions</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">qvalues</span><span class="p">)]</span>
            <span class="c1">#_logger.debug(&quot;action %s &lt;-- Qvalues: %s&quot; % (str(action),str(qvalues)))</span>
        <span class="c1"># perform the action</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">get_current_frame</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
        <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">is_state_terminal</span><span class="p">()</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Observation: action=</span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">), reward=</span><span class="si">%s</span><span class="s2">, frame_dims=</span><span class="si">%s</span><span class="s2">, just_lost_live=</span><span class="si">%s</span><span class="s2">, terminal=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">how</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">reward</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">just_lost_live</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">terminal</span><span class="p">)</span> <span class="p">))</span>

        <span class="c1"># TODO: check if lost live to end episode</span>
        <span class="c1">#if self.has_just_lost_live:</span>

        <span class="c1"># restart the game if over</span>
        <span class="k">if</span> <span class="n">terminal</span><span class="p">:</span>
            <span class="c1">#_logger.debug(&quot;GAME OVER: reached terminal state --&gt; restarting&quot;)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_do_dummy_steps</span><span class="p">()</span>

        <span class="c1"># call callback to record statistics</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">from_agent</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">terminal</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">terminal</span></div>

<div class="viewcode-block" id="AtariAgent.populate_mem"><a class="viewcode-back" href="../../../modules/agent.html#deepatari.agents.atariagent.AtariAgent.populate_mem">[docs]</a>    <span class="k">def</span> <span class="nf">populate_mem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Play a given number of steps to prefill the replay memory</span>

<span class="sd">        Args:</span>
<span class="sd">            size (int): The desired size of the memory initialization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Playing without exploitation for </span><span class="si">%d</span><span class="s2"> steps &quot;</span> <span class="o">%</span> <span class="n">size</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
            <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mem</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">terminal</span><span class="p">)</span></div>

<div class="viewcode-block" id="AtariAgent.train"><a class="viewcode-back" href="../../../modules/agent.html#deepatari.agents.atariagent.AtariAgent.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Performs a complete training epoch, filling the replay memory and calling the network train function.</span>

<span class="sd">        Args:</span>
<span class="sd">            steps (int): The number of steps.</span>
<span class="sd">            epoch (int): The current epoch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Training epoch </span><span class="si">%d</span><span class="s2"> for </span><span class="si">%d</span><span class="s2"> steps&quot;</span> <span class="o">%</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">steps</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="c1"># perform game step</span>
            <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_update_epsilon</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mem</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">terminal</span><span class="p">)</span>
            <span class="c1"># train after every train_frequency steps</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mem</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">mem</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frequency</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_repeat</span><span class="p">):</span>
                    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">followup_states</span><span class="p">,</span> <span class="n">terminals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mem</span><span class="o">.</span><span class="n">get_minibatch</span><span class="p">()</span>

                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_all</span><span class="p">:</span>
                        <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
                                <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avail_actions</span> <span class="o">==</span> <span class="n">action</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">],</span>
                                <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
                    <span class="c1"># train the network</span>
                    <span class="n">minibatch</span> <span class="o">=</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">followup_states</span><span class="p">,</span> <span class="n">terminals</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">minibatch</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="c1"># increase number of training steps for epsilon decay</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_steps_total</span> <span class="o">+=</span> <span class="mi">1</span></div>

<div class="viewcode-block" id="AtariAgent.test"><a class="viewcode-back" href="../../../modules/agent.html#deepatari.agents.atariagent.AtariAgent.test">[docs]</a>    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Performs a complete testing epoch.</span>

<span class="sd">        Args:</span>
<span class="sd">            steps (int): The number of steps.</span>
<span class="sd">            epoch (int): The current epoch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># just make sure there is sequence_length frames to form a state</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Testing epoch </span><span class="si">%d</span><span class="s2"> for </span><span class="si">%d</span><span class="s2"> steps&quot;</span> <span class="o">%</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">steps</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_do_dummy_steps</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_test</span><span class="p">)</span></div>

<div class="viewcode-block" id="AtariAgent.play"><a class="viewcode-back" href="../../../modules/agent.html#deepatari.agents.atariagent.AtariAgent.play">[docs]</a>    <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_games</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Plays the game for a num_games times.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_games (int): The number of games to play until stop.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Playing without exploration for </span><span class="si">%d</span><span class="s2"> games &quot;</span> <span class="o">%</span> <span class="n">num_games</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_do_dummy_steps</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">num_games</span><span class="p">):</span>
            <span class="n">terminal</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">while</span> <span class="ow">not</span> <span class="n">terminal</span><span class="p">:</span>
                <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">frame</span><span class="p">,</span> <span class="n">terminal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epsilon_test</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Ruben Glatt.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>